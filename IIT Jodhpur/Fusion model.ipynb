{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c44a68-a346-4973-be61-572e1df6f37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.20.0\n",
      "Train dir: C:\\Users\\ACIL\\Documents\\IITJ\\Working\\archive (2)\\train\n",
      "Val dir  : C:\\Users\\ACIL\\Documents\\IITJ\\Working\\archive (2)\\test\n",
      "Found 24176 images belonging to 5 classes.\n",
      "Found 6043 images belonging to 5 classes.\n",
      "Detected classes: {'angry': 0, 'happy': 1, 'neutral': 2, 'sad': 3, 'surprise': 4}\n",
      "num_classes = 5\n",
      "Saved class_indices_fusion.json\n",
      "Loading CNN from: C:\\Users\\ACIL\\Documents\\IITJ\\Emotion_little_vgg.h5\n",
      "Loading TCN from: C:\\Users\\ACIL\\Documents\\IITJ\\Working\\emotion_tcn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN input shape: (None, 48, 48, 1)\n",
      "CNN output shape: (None, 5)\n",
      "TCN input shape: (None, 48, 48, 1)\n",
      "TCN output shape: (None, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cnn_tcn_fusion\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cnn_tcn_fusion\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ fusion_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,328,037</span> │ fusion_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emotion_tcn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">80,197</span> │ fusion_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concat_cnn_tcn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                               │                           │                 │ emotion_tcn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ fusion_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ concat_cnn_tcn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ fusion_softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ fusion_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_4 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │       \u001b[38;5;34m1,328,037\u001b[0m │ fusion_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emotion_tcn (\u001b[38;5;33mFunctional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │          \u001b[38;5;34m80,197\u001b[0m │ fusion_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concat_cnn_tcn (\u001b[38;5;33mConcatenate\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ sequential_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                               │                           │                 │ emotion_tcn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ fusion_dense (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m704\u001b[0m │ concat_cnn_tcn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ fusion_softmax (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m325\u001b[0m │ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,409,263</span> (5.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,409,263\u001b[0m (5.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,029</span> (4.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,029\u001b[0m (4.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408,234</span> (5.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,408,234\u001b[0m (5.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.3754 - loss: 1.5056\n",
      "Epoch 1: val_loss improved from None to 1.20455, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 106ms/step - accuracy: 0.4952 - loss: 1.4120 - val_accuracy: 0.6675 - val_loss: 1.2045 - learning_rate: 1.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.6696 - loss: 1.1621\n",
      "Epoch 2: val_loss improved from 1.20455 to 0.94937, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 118ms/step - accuracy: 0.6727 - loss: 1.1018 - val_accuracy: 0.6910 - val_loss: 0.9494 - learning_rate: 1.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.6733 - loss: 0.9626\n",
      "Epoch 3: val_loss improved from 0.94937 to 0.85641, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 123ms/step - accuracy: 0.6744 - loss: 0.9392 - val_accuracy: 0.6909 - val_loss: 0.8564 - learning_rate: 1.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6749 - loss: 0.8908\n",
      "Epoch 4: val_loss improved from 0.85641 to 0.82761, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 102ms/step - accuracy: 0.6746 - loss: 0.8852 - val_accuracy: 0.6914 - val_loss: 0.8276 - learning_rate: 1.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6769 - loss: 0.8683\n",
      "Epoch 5: val_loss improved from 0.82761 to 0.81687, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 101ms/step - accuracy: 0.6797 - loss: 0.8596 - val_accuracy: 0.6939 - val_loss: 0.8169 - learning_rate: 1.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6802 - loss: 0.8501\n",
      "Epoch 6: val_loss improved from 0.81687 to 0.81474, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 104ms/step - accuracy: 0.6789 - loss: 0.8546 - val_accuracy: 0.6932 - val_loss: 0.8147 - learning_rate: 1.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6788 - loss: 0.8493\n",
      "Epoch 7: val_loss improved from 0.81474 to 0.81271, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 102ms/step - accuracy: 0.6796 - loss: 0.8484 - val_accuracy: 0.6929 - val_loss: 0.8127 - learning_rate: 1.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.6728 - loss: 0.8543\n",
      "Epoch 8: val_loss improved from 0.81271 to 0.81111, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 112ms/step - accuracy: 0.6768 - loss: 0.8509 - val_accuracy: 0.6942 - val_loss: 0.8111 - learning_rate: 1.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6801 - loss: 0.8431\n",
      "Epoch 9: val_loss did not improve from 0.81111\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 106ms/step - accuracy: 0.6822 - loss: 0.8435 - val_accuracy: 0.6939 - val_loss: 0.8114 - learning_rate: 1.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.6777 - loss: 0.8537\n",
      "Epoch 10: val_loss improved from 0.81111 to 0.81022, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 124ms/step - accuracy: 0.6799 - loss: 0.8429 - val_accuracy: 0.6950 - val_loss: 0.8102 - learning_rate: 1.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6801 - loss: 0.8504\n",
      "Epoch 11: val_loss improved from 0.81022 to 0.80920, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 128ms/step - accuracy: 0.6796 - loss: 0.8453 - val_accuracy: 0.6953 - val_loss: 0.8092 - learning_rate: 1.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.6804 - loss: 0.8461\n",
      "Epoch 12: val_loss improved from 0.80920 to 0.80913, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 111ms/step - accuracy: 0.6824 - loss: 0.8429 - val_accuracy: 0.6945 - val_loss: 0.8091 - learning_rate: 1.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6813 - loss: 0.8384\n",
      "Epoch 13: val_loss improved from 0.80913 to 0.80856, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 108ms/step - accuracy: 0.6825 - loss: 0.8401 - val_accuracy: 0.6950 - val_loss: 0.8086 - learning_rate: 1.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.6826 - loss: 0.8468\n",
      "Epoch 14: val_loss did not improve from 0.80856\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 111ms/step - accuracy: 0.6835 - loss: 0.8408 - val_accuracy: 0.6960 - val_loss: 0.8088 - learning_rate: 1.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.6796 - loss: 0.8432\n",
      "Epoch 15: val_loss improved from 0.80856 to 0.80798, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 111ms/step - accuracy: 0.6823 - loss: 0.8400 - val_accuracy: 0.6957 - val_loss: 0.8080 - learning_rate: 1.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.6800 - loss: 0.8407\n",
      "Epoch 16: val_loss did not improve from 0.80798\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 118ms/step - accuracy: 0.6809 - loss: 0.8384 - val_accuracy: 0.6957 - val_loss: 0.8083 - learning_rate: 1.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.6798 - loss: 0.8460\n",
      "Epoch 17: val_loss did not improve from 0.80798\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 121ms/step - accuracy: 0.6828 - loss: 0.8399 - val_accuracy: 0.6960 - val_loss: 0.8084 - learning_rate: 1.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6835 - loss: 0.8424\n",
      "Epoch 18: val_loss improved from 0.80798 to 0.80665, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 139ms/step - accuracy: 0.6852 - loss: 0.8359 - val_accuracy: 0.6968 - val_loss: 0.8066 - learning_rate: 1.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.6804 - loss: 0.8438\n",
      "Epoch 19: val_loss improved from 0.80665 to 0.80660, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 126ms/step - accuracy: 0.6836 - loss: 0.8339 - val_accuracy: 0.6953 - val_loss: 0.8066 - learning_rate: 1.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6846 - loss: 0.8277\n",
      "Epoch 20: val_loss improved from 0.80660 to 0.80648, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 137ms/step - accuracy: 0.6826 - loss: 0.8367 - val_accuracy: 0.6955 - val_loss: 0.8065 - learning_rate: 1.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.6805 - loss: 0.8351\n",
      "Epoch 21: val_loss improved from 0.80648 to 0.80546, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 149ms/step - accuracy: 0.6812 - loss: 0.8383 - val_accuracy: 0.6973 - val_loss: 0.8055 - learning_rate: 1.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.6845 - loss: 0.8330\n",
      "Epoch 22: val_loss did not improve from 0.80546\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 150ms/step - accuracy: 0.6813 - loss: 0.8385 - val_accuracy: 0.6957 - val_loss: 0.8057 - learning_rate: 1.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.6798 - loss: 0.8487\n",
      "Epoch 23: val_loss did not improve from 0.80546\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 148ms/step - accuracy: 0.6827 - loss: 0.8395 - val_accuracy: 0.6952 - val_loss: 0.8063 - learning_rate: 1.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.6816 - loss: 0.8382\n",
      "Epoch 24: val_loss did not improve from 0.80546\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 146ms/step - accuracy: 0.6826 - loss: 0.8390 - val_accuracy: 0.6944 - val_loss: 0.8069 - learning_rate: 1.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.6903 - loss: 0.8222\n",
      "Epoch 25: val_loss did not improve from 0.80546\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 151ms/step - accuracy: 0.6852 - loss: 0.8334 - val_accuracy: 0.6958 - val_loss: 0.8060 - learning_rate: 2.0000e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6790 - loss: 0.8474\n",
      "Epoch 26: val_loss did not improve from 0.80546\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 149ms/step - accuracy: 0.6829 - loss: 0.8407 - val_accuracy: 0.6963 - val_loss: 0.8059 - learning_rate: 2.0000e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.6832 - loss: 0.8352\n",
      "Epoch 27: val_loss did not improve from 0.80546\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 150ms/step - accuracy: 0.6814 - loss: 0.8379 - val_accuracy: 0.6958 - val_loss: 0.8055 - learning_rate: 2.0000e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6850 - loss: 0.8295\n",
      "Epoch 28: val_loss improved from 0.80546 to 0.80545, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 149ms/step - accuracy: 0.6833 - loss: 0.8350 - val_accuracy: 0.6960 - val_loss: 0.8055 - learning_rate: 4.0000e-06\n",
      "Epoch 29/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6826 - loss: 0.8467\n",
      "Epoch 29: val_loss improved from 0.80545 to 0.80540, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 149ms/step - accuracy: 0.6821 - loss: 0.8390 - val_accuracy: 0.6958 - val_loss: 0.8054 - learning_rate: 4.0000e-06\n",
      "Epoch 30/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.6790 - loss: 0.8360\n",
      "Epoch 30: val_loss improved from 0.80540 to 0.80536, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 152ms/step - accuracy: 0.6799 - loss: 0.8377 - val_accuracy: 0.6960 - val_loss: 0.8054 - learning_rate: 4.0000e-06\n",
      "Epoch 31/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.6850 - loss: 0.8401\n",
      "Epoch 31: val_loss improved from 0.80536 to 0.80535, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 151ms/step - accuracy: 0.6842 - loss: 0.8347 - val_accuracy: 0.6960 - val_loss: 0.8053 - learning_rate: 4.0000e-06\n",
      "Epoch 32/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6865 - loss: 0.8295\n",
      "Epoch 32: val_loss did not improve from 0.80535\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 149ms/step - accuracy: 0.6826 - loss: 0.8397 - val_accuracy: 0.6960 - val_loss: 0.8054 - learning_rate: 4.0000e-06\n",
      "Epoch 33/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.6795 - loss: 0.8313\n",
      "Epoch 33: val_loss improved from 0.80535 to 0.80534, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 148ms/step - accuracy: 0.6830 - loss: 0.8348 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 4.0000e-06\n",
      "Epoch 34/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6787 - loss: 0.8451\n",
      "Epoch 34: val_loss did not improve from 0.80534\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 149ms/step - accuracy: 0.6815 - loss: 0.8397 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 8.0000e-07\n",
      "Epoch 35/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.6841 - loss: 0.8362\n",
      "Epoch 35: val_loss did not improve from 0.80534\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 150ms/step - accuracy: 0.6849 - loss: 0.8352 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 8.0000e-07\n",
      "Epoch 36/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.6799 - loss: 0.8373\n",
      "Epoch 36: val_loss improved from 0.80534 to 0.80533, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 149ms/step - accuracy: 0.6830 - loss: 0.8384 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 8.0000e-07\n",
      "Epoch 37/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.6833 - loss: 0.8361\n",
      "Epoch 37: val_loss improved from 0.80533 to 0.80533, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 150ms/step - accuracy: 0.6840 - loss: 0.8349 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 1.6000e-07\n",
      "Epoch 38/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.6866 - loss: 0.8374\n",
      "Epoch 38: val_loss improved from 0.80533 to 0.80533, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 152ms/step - accuracy: 0.6825 - loss: 0.8392 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 1.6000e-07\n",
      "Epoch 39/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.6838 - loss: 0.8311\n",
      "Epoch 39: val_loss improved from 0.80533 to 0.80533, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 148ms/step - accuracy: 0.6813 - loss: 0.8374 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 1.6000e-07\n",
      "Epoch 40/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.6820 - loss: 0.8381\n",
      "Epoch 40: val_loss improved from 0.80533 to 0.80533, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 151ms/step - accuracy: 0.6825 - loss: 0.8346 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 3.2000e-08\n",
      "Epoch 41/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.6820 - loss: 0.8441\n",
      "Epoch 41: val_loss improved from 0.80533 to 0.80533, saving model to emotion_fusion.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 151ms/step - accuracy: 0.6855 - loss: 0.8339 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 3.2000e-08\n",
      "Epoch 42/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6878 - loss: 0.8247\n",
      "Epoch 42: val_loss did not improve from 0.80533\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 149ms/step - accuracy: 0.6839 - loss: 0.8300 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 3.2000e-08\n",
      "Epoch 43/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6849 - loss: 0.8386\n",
      "Epoch 43: val_loss did not improve from 0.80533\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 149ms/step - accuracy: 0.6842 - loss: 0.8367 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 6.4000e-09\n",
      "Epoch 44/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6861 - loss: 0.8347\n",
      "Epoch 44: val_loss did not improve from 0.80533\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 149ms/step - accuracy: 0.6841 - loss: 0.8365 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 6.4000e-09\n",
      "Epoch 45/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6786 - loss: 0.8402\n",
      "Epoch 45: val_loss did not improve from 0.80533\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 1.279999928271991e-09.\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 149ms/step - accuracy: 0.6840 - loss: 0.8366 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 6.4000e-09\n",
      "Epoch 46/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.6796 - loss: 0.8483\n",
      "Epoch 46: val_loss did not improve from 0.80533\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 150ms/step - accuracy: 0.6828 - loss: 0.8370 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 1.2800e-09\n",
      "Epoch 47/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6758 - loss: 0.8491\n",
      "Epoch 47: val_loss did not improve from 0.80533\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 149ms/step - accuracy: 0.6839 - loss: 0.8368 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 1.2800e-09\n",
      "Epoch 48/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.6864 - loss: 0.8401\n",
      "Epoch 48: val_loss did not improve from 0.80533\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 2.55999976772614e-10.\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 151ms/step - accuracy: 0.6846 - loss: 0.8383 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 1.2800e-09\n",
      "Epoch 49/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.6861 - loss: 0.8343\n",
      "Epoch 49: val_loss did not improve from 0.80533\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 141ms/step - accuracy: 0.6845 - loss: 0.8345 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 2.5600e-10\n",
      "Epoch 50/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.6812 - loss: 0.8347\n",
      "Epoch 50: val_loss did not improve from 0.80533\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 158ms/step - accuracy: 0.6821 - loss: 0.8379 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 2.5600e-10\n",
      "Epoch 51/60\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.6875 - loss: 0.8276\n",
      "Epoch 51: val_loss did not improve from 0.80533\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 5.119999424429978e-11.\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 150ms/step - accuracy: 0.6846 - loss: 0.8362 - val_accuracy: 0.6962 - val_loss: 0.8053 - learning_rate: 2.5600e-10\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 86ms/step - accuracy: 0.6962 - loss: 0.8053\n",
      "Fusion validation accuracy: 69.62%\n",
      "Best Fusion model saved as: emotion_fusion.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Concatenate, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "\n",
    "# ============================\n",
    "# 1. BASIC CONFIG\n",
    "# ============================\n",
    "\n",
    "img_rows, img_cols = 48, 48\n",
    "batch_size = 32\n",
    "\n",
    "# 🔴 IMPORTANT: apna correct dataset path\n",
    "BASE_DIR = r\"C:\\Users\\ACIL\\Documents\\IITJ\\Working\\archive (2)\"\n",
    "train_data_dir = os.path.join(BASE_DIR, \"train\")\n",
    "validation_data_dir = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "print(\"Train dir:\", train_data_dir)\n",
    "print(\"Val dir  :\", validation_data_dir)\n",
    "\n",
    "if not os.path.isdir(train_data_dir):\n",
    "    raise FileNotFoundError(f\"Train directory not found: {train_data_dir}\")\n",
    "if not os.path.isdir(validation_data_dir):\n",
    "    raise FileNotFoundError(f\"Validation directory not found: {validation_data_dir}\")\n",
    "\n",
    "# ============================\n",
    "# 2. DATA GENERATORS\n",
    "# ============================\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "num_classes = train_generator.num_classes\n",
    "print(\"Detected classes:\", train_generator.class_indices)\n",
    "print(\"num_classes =\", num_classes)\n",
    "\n",
    "# Optional: save class indices for fusion as well\n",
    "with open(\"class_indices_fusion.json\", \"w\") as f:\n",
    "    json.dump(train_generator.class_indices, f)\n",
    "print(\"Saved class_indices_fusion.json\")\n",
    "\n",
    "# ============================\n",
    "# 3. LOAD PRETRAINED CNN & TCN\n",
    "# ============================\n",
    "\n",
    "cnn_path = r\"C:\\Users\\ACIL\\Documents\\IITJ\\Emotion_little_vgg.h5\"\n",
    "tcn_path = r\"C:\\Users\\ACIL\\Documents\\IITJ\\Working\\emotion_tcn.h5\"\n",
    "\n",
    "print(\"Loading CNN from:\", cnn_path)\n",
    "print(\"Loading TCN from:\", tcn_path)\n",
    "\n",
    "cnn_model = load_model(cnn_path)\n",
    "tcn_model = load_model(tcn_path)\n",
    "\n",
    "print(\"CNN input shape:\", cnn_model.input_shape)\n",
    "print(\"CNN output shape:\", cnn_model.output_shape)\n",
    "print(\"TCN input shape:\", tcn_model.input_shape)\n",
    "print(\"TCN output shape:\", tcn_model.output_shape)\n",
    "\n",
    "# Freeze CNN & TCN weights (sirf fusion head train hoga)\n",
    "for layer in cnn_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in tcn_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# ============================\n",
    "# 4. BUILD FUSION MODEL\n",
    "# ============================\n",
    "\n",
    "# Common input for both models\n",
    "fusion_input = Input(shape=(img_rows, img_cols, 1), name=\"fusion_input\")\n",
    "\n",
    "# Pass same input through both pretrained models\n",
    "cnn_out = cnn_model(fusion_input)   # shape: (None, num_classes)\n",
    "tcn_out = tcn_model(fusion_input)   # shape: (None, num_classes)\n",
    "\n",
    "# Concatenate their outputs (feature-level fusion)\n",
    "combined = Concatenate(name=\"concat_cnn_tcn\")([cnn_out, tcn_out])  # shape: (None, 2 * num_classes)\n",
    "\n",
    "# Small fusion head\n",
    "x = Dense(64, activation=\"relu\", name=\"fusion_dense\")(combined)\n",
    "fusion_output = Dense(num_classes, activation=\"softmax\", name=\"fusion_softmax\")(x)\n",
    "\n",
    "fusion_model = Model(inputs=fusion_input, outputs=fusion_output, name=\"cnn_tcn_fusion\")\n",
    "fusion_model.summary()\n",
    "\n",
    "# ============================\n",
    "# 5. COMPILE\n",
    "# ============================\n",
    "\n",
    "fusion_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 6. CALLBACKS\n",
    "# ============================\n",
    "\n",
    "fusion_model_path = \"emotion_fusion.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    fusion_model_path,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "earlystop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_delta=1e-4,\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, earlystop, reduce_lr]\n",
    "\n",
    "# ============================\n",
    "# 7. TRAIN FUSION MODEL\n",
    "# ============================\n",
    "\n",
    "nb_train_samples = train_generator.samples\n",
    "nb_validation_samples = validation_generator.samples\n",
    "\n",
    "steps_per_epoch = math.ceil(nb_train_samples / batch_size)\n",
    "val_steps = math.ceil(nb_validation_samples / batch_size)\n",
    "\n",
    "epochs = 60\n",
    "\n",
    "history = fusion_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_steps,\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 8. EVALUATE\n",
    "# ============================\n",
    "\n",
    "val_loss, val_acc = fusion_model.evaluate(\n",
    "    validation_generator,\n",
    "    steps=val_steps,\n",
    ")\n",
    "print(f\"Fusion validation accuracy: {val_acc * 100:.2f}%\")\n",
    "print(\"Best Fusion model saved as:\", fusion_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbf660-82cc-41cd-8ca3-81cdbe095b32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfenv)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
